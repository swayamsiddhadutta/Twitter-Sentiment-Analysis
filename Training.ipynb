{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>love guys the best</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>im meeting up with one of my besties tonight c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>thanks for the twitter add sunisa got to meet ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>being sick can be really cheap when it hurts t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800004</th>\n",
       "      <td>he has that effect on everyone</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  target\n",
       "800000                                 love guys the best       4\n",
       "800001  im meeting up with one of my besties tonight c...       4\n",
       "800002  thanks for the twitter add sunisa got to meet ...       4\n",
       "800003  being sick can be really cheap when it hurts t...       4\n",
       "800004                     he has that effect on everyone       4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "my_df = pd.read_csv(r'C:\\Users\\Swayam Dutta\\Desktop\\Sentiment Analysis\\clean_tweet.csv',encoding='latin1',index_col=0)\n",
    "my_df[my_df.target == 4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3959"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(my_df.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       True\n",
       "target    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "x = my_df.text\n",
    "y = my_df.target\n",
    "from sklearn.cross_validation import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 1564120 entries with 50.02% negative, 49.98% positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set has total %d entries with %.2f%% negative, %.2f%% positive\"%(len(x_train),                                                                     \n",
    "(len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
    "(len(x_train[y_train == 4]) / (len(x_train)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set has total 15960 entries with 49.45% negative, 50.55% positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation set has total %d entries with %.2f%% negative, %.2f%% positive\"%(len(x_validation),                                    \n",
    "(len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,                                                                       \n",
    "(len(x_validation[y_validation == 4]) / (len(x_validation)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has total 15961 entries with 49.68% negative, 50.32% positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set has total %d entries with %.2f%% negative, %.2f%% positive\"%(len(x_test), \n",
    "(len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
    "(len(x_test[y_test == 4]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbresult = [TextBlob(str(i)).sentiment.polarity for i in x_validation]\n",
    "tbpred = [0 if n < 0 else 4 for n in tbresult]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conmat = np.array(confusion_matrix(y_validation, tbpred, labels=[4,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion = pd.DataFrame(conmat, index=['positive', 'negative'],columns=['predicted_positive','predicted_negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 61.84%\n",
      "--------------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "          predicted_positive  predicted_negative\n",
      "positive                7282                 785\n",
      "negative                5306                2587\n",
      "--------------------------------------------------------------------------------\n",
      "Classification Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.33      0.46      7893\n",
      "          4       0.58      0.90      0.71      8067\n",
      "\n",
      "avg / total       0.67      0.62      0.58     15960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score: %.2f%%\"%(accuracy_score(y_validation, tbpred)*100))\n",
    "print(\"-\"*80)\n",
    "print(\"Confusion Matrix\\n\")\n",
    "print(confusion)\n",
    "print(\"-\"*80)\n",
    "print(\"Classification Report\\n\")\n",
    "print(classification_report(y_validation, tbpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test == 0]) / (len(x_test)*1.) > 0.5:\n",
    "        null_accuracy = len(x_test[y_test == 0]) / (len(x_test)*1.)\n",
    "    else:\n",
    "        null_accuracy = 1. - (len(x_test[y_test == 0]) / (len(x_test)*1.))\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"null accuracy: %.2f%%\"%(null_accuracy*100))\n",
    "    print(\"accuracy score: %.2f%%\"%(accuracy*100))\n",
    "    if accuracy > null_accuracy:\n",
    "        print(\"model is %.2f%% more accurate than null accuracy\"%((accuracy-null_accuracy)*100))\n",
    "    elif accuracy == null_accuracy:\n",
    "        print(\"model has the same accuracy with the null accuracy\")\n",
    "    else:\n",
    "        print(\"model is %.2f%% less accurate than null accuracy\"%((null_accuracy-accuracy)*100))\n",
    "    print(\"train and test time: %.2fs\"%(train_test_time))\n",
    "    print(\"-\"*80)\n",
    "    return accuracy, train_test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "lr = LogisticRegression()\n",
    "n_features = np.arange(10000,100001,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nfeature_accuracy_checker(vectorizer=cvec, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=lr):\n",
    "    result = []\n",
    "    print(classifier)\n",
    "    print(\"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        print(\"Validation result for %d features\"%(n))\n",
    "        nfeature_accuracy,tt_time = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        result.append((n,nfeature_accuracy,tt_time))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>313162</td>\n",
       "      <td>252567</td>\n",
       "      <td>565729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>257836</td>\n",
       "      <td>265998</td>\n",
       "      <td>523834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>190775</td>\n",
       "      <td>125955</td>\n",
       "      <td>316730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>157448</td>\n",
       "      <td>147786</td>\n",
       "      <td>305234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>153958</td>\n",
       "      <td>149642</td>\n",
       "      <td>303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>103844</td>\n",
       "      <td>198245</td>\n",
       "      <td>302089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>194724</td>\n",
       "      <td>86861</td>\n",
       "      <td>281585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>133432</td>\n",
       "      <td>111191</td>\n",
       "      <td>244623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>115542</td>\n",
       "      <td>101160</td>\n",
       "      <td>216702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>98999</td>\n",
       "      <td>117369</td>\n",
       "      <td>216368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     negative  positive   total\n",
       "to     313162    252567  565729\n",
       "the    257836    265998  523834\n",
       "my     190775    125955  316730\n",
       "it     157448    147786  305234\n",
       "and    153958    149642  303600\n",
       "you    103844    198245  302089\n",
       "not    194724     86861  281585\n",
       "is     133432    111191  244623\n",
       "in     115542    101160  216702\n",
       "for     98999    117369  216368"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = r'C:\\Users\\Swayam Dutta\\Desktop\\Sentiment Analysis\\term_freq_df.csv'\n",
    "term_freq_df = pd.read_csv(csv,index_col=0)\n",
    "term_freq_df.sort_values(by='total', ascending=False).iloc[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_stop_words = frozenset(list(term_freq_df.sort_values(by='total', ascending=False).iloc[:10].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR UNIGRAM WITHOUT STOP WORDS\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.34%\n",
      "model is 26.80% more accurate than null accuracy\n",
      "train and test time: 139.27s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.66%\n",
      "model is 27.11% more accurate than null accuracy\n",
      "train and test time: 148.94s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.78%\n",
      "model is 27.24% more accurate than null accuracy\n",
      "train and test time: 163.59s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.72%\n",
      "model is 27.17% more accurate than null accuracy\n",
      "train and test time: 189.57s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.74%\n",
      "model is 27.20% more accurate than null accuracy\n",
      "train and test time: 193.32s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.86%\n",
      "model is 27.31% more accurate than null accuracy\n",
      "train and test time: 187.43s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.86%\n",
      "model is 27.31% more accurate than null accuracy\n",
      "train and test time: 181.41s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.78%\n",
      "model is 27.24% more accurate than null accuracy\n",
      "train and test time: 228.78s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.79%\n",
      "model is 27.25% more accurate than null accuracy\n",
      "train and test time: 226.86s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 77.77%\n",
      "model is 27.22% more accurate than null accuracy\n",
      "train and test time: 212.75s\n",
      "--------------------------------------------------------------------------------\n",
      "RESULT FOR UNIGRAM WITH STOP WORDS\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.66%\n",
      "model is 29.11% more accurate than null accuracy\n",
      "train and test time: 223.53s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.82%\n",
      "model is 29.27% more accurate than null accuracy\n",
      "train and test time: 290.02s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.76%\n",
      "model is 29.21% more accurate than null accuracy\n",
      "train and test time: 318.66s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.77%\n",
      "model is 29.23% more accurate than null accuracy\n",
      "train and test time: 284.11s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.83%\n",
      "model is 29.29% more accurate than null accuracy\n",
      "train and test time: 311.60s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.87%\n",
      "model is 29.33% more accurate than null accuracy\n",
      "train and test time: 399.68s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.94%\n",
      "model is 29.39% more accurate than null accuracy\n",
      "train and test time: 348.77s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.96%\n",
      "model is 29.41% more accurate than null accuracy\n",
      "train and test time: 431.47s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 80.01%\n",
      "model is 29.47% more accurate than null accuracy\n",
      "train and test time: 434.36s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 80.01%\n",
      "model is 29.47% more accurate than null accuracy\n",
      "train and test time: 441.70s\n",
      "--------------------------------------------------------------------------------\n",
      "RESULT FOR UNIGRAM WITHOUT CUSTOM STOP WORDS (Top 10 frequent words)\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 78.84%\n",
      "model is 28.30% more accurate than null accuracy\n",
      "train and test time: 172.16s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.00%\n",
      "model is 28.45% more accurate than null accuracy\n",
      "train and test time: 193.00s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.04%\n",
      "model is 28.49% more accurate than null accuracy\n",
      "train and test time: 226.04s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.05%\n",
      "model is 28.51% more accurate than null accuracy\n",
      "train and test time: 253.69s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.04%\n",
      "model is 28.49% more accurate than null accuracy\n",
      "train and test time: 284.68s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.10%\n",
      "model is 28.56% more accurate than null accuracy\n",
      "train and test time: 281.34s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.11%\n",
      "model is 28.57% more accurate than null accuracy\n",
      "train and test time: 266.18s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.10%\n",
      "model is 28.55% more accurate than null accuracy\n",
      "train and test time: 320.72s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.05%\n",
      "model is 28.50% more accurate than null accuracy\n",
      "train and test time: 323.50s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 79.04%\n",
      "model is 28.49% more accurate than null accuracy\n",
      "train and test time: 332.83s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"RESULT FOR UNIGRAM WITHOUT STOP WORDS\\n\")\n",
    "feature_result_wosw = nfeature_accuracy_checker(stop_words='english')\n",
    "print(\"RESULT FOR UNIGRAM WITH STOP WORDS\\n\")\n",
    "feature_result_ug = nfeature_accuracy_checker()\n",
    "print(\"RESULT FOR UNIGRAM WITHOUT CUSTOM STOP WORDS (Top 10 frequent words)\\n\")\n",
    "feature_result_wocsw = nfeature_accuracy_checker(stop_words=my_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfeatures_plot_ug = pd.DataFrame(feature_result_ug,columns=['nfeatures','validation_accuracy','train_test_time'])\n",
    "nfeatures_plot_ug_wocsw = pd.DataFrame(feature_result_wocsw,columns=['nfeatures','validation_accuracy','train_test_time'])\n",
    "nfeatures_plot_ug_wosw = pd.DataFrame(feature_result_wosw,columns=['nfeatures','validation_accuracy','train_test_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27080c764e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(nfeatures_plot_ug.nfeatures, nfeatures_plot_ug.validation_accuracy, label='with stop words')\n",
    "plt.plot(nfeatures_plot_ug_wocsw.nfeatures, nfeatures_plot_ug_wocsw.validation_accuracy,label='without custom stop words')\n",
    "plt.plot(nfeatures_plot_ug_wosw.nfeatures, nfeatures_plot_ug_wosw.validation_accuracy,label='without stop words')\n",
    "plt.title(\"Without stop words VS With stop words (Unigram): Accuracy\")\n",
    "plt.xlabel(\"Number of features\")\n",
    "plt.ylabel(\"Validation set accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAGDCAYAAABZQXgsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x270805d54e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR BIGRAM WITH STOP WORDS\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 80.58%\n",
      "model is 30.04% more accurate than null accuracy\n",
      "train and test time: 371.89s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 81.39%\n",
      "model is 30.85% more accurate than null accuracy\n",
      "train and test time: 432.76s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 81.79%\n",
      "model is 31.25% more accurate than null accuracy\n",
      "train and test time: 352.41s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 81.91%\n",
      "model is 31.37% more accurate than null accuracy\n",
      "train and test time: 457.93s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 81.94%\n",
      "model is 31.40% more accurate than null accuracy\n",
      "train and test time: 676.90s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 82.00%\n",
      "model is 31.45% more accurate than null accuracy\n",
      "train and test time: 761.92s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 82.22%\n",
      "model is 31.67% more accurate than null accuracy\n",
      "train and test time: 1588.92s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 82.05%\n",
      "model is 31.50% more accurate than null accuracy\n",
      "train and test time: 1222.03s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 82.14%\n",
      "model is 31.59% more accurate than null accuracy\n",
      "train and test time: 1122.64s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 50.55%\n",
      "accuracy score: 82.17%\n",
      "model is 31.63% more accurate than null accuracy\n",
      "train and test time: 1332.61s\n",
      "--------------------------------------------------------------------------------\n",
      "RESULT FOR TRIGRAM WITH STOP WORDS\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n"
     ]
    }
   ],
   "source": [
    "print(\"RESULT FOR BIGRAM WITH STOP WORDS\\n\")\n",
    "feature_result_bg = nfeature_accuracy_checker(ngram_range=(1, 2))\n",
    "print(\"RESULT FOR TRIGRAM WITH STOP WORDS\\n\")\n",
    "feature_result_tg = nfeature_accuracy_checker(ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
