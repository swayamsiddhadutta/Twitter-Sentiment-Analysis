{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_string</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mybirch</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>coZZ</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>2Hood4Hollywood</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mimismo</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date query_string  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009     NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009     NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009     NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
       "5          0  1467811372  Mon Apr 06 22:20:00 PDT 2009     NO_QUERY   \n",
       "6          0  1467811592  Mon Apr 06 22:20:03 PDT 2009     NO_QUERY   \n",
       "7          0  1467811594  Mon Apr 06 22:20:03 PDT 2009     NO_QUERY   \n",
       "8          0  1467811795  Mon Apr 06 22:20:05 PDT 2009     NO_QUERY   \n",
       "9          0  1467812025  Mon Apr 06 22:20:09 PDT 2009     NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "5         joy_wolf                      @Kwesidei not the whole crew   \n",
       "6          mybirch                                        Need a hug   \n",
       "7             coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
       "8  2Hood4Hollywood               @Tatiana_K nope they didn't have it   \n",
       "9          mimismo                          @twittera que me muera ?   "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "cols = ['sentiment','id','date','query_string','user','text']\n",
    "df = pd.read_csv(r'C:\\Users\\Swayam Dutta\\Desktop\\Sentiment Analysis\\trainingandtestdata\\training.1600000.processed.noemoticon.csv',header=None,names=cols,encoding=\"latin1\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['id','date','query_string','user'],axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>4</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>4</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>4</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>4</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800004</th>\n",
       "      <td>4</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                               text\n",
       "800000          4       I LOVE @Health4UandPets u guys r the best!! \n",
       "800001          4  im meeting up with one of my besties tonight! ...\n",
       "800002          4  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "800003          4  Being sick can be really cheap when it hurts t...\n",
       "800004          4    @LovesBrooklyn2 he has that effect on everyone "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 4].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  pre_clean_len\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...            115\n",
       "1          0  is upset that he can't update his Facebook by ...            111\n",
       "2          0  @Kenichan I dived many times for the ball. Man...             89\n",
       "3          0    my whole body feels itchy and like its on fire              47\n",
       "4          0  @nationwideclass no, it's not behaving at all....            111"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre_clean_len'] = [len(t) for t in df.text]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>pre_clean_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>Awwh babs... you look so sad underneith that s...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuesdayï¿½ll start with reflection ï¿½n then a...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>Whinging. My client&amp;amp;boss don't understand ...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>@TheLeagueSF Not Fun &amp;amp; Furious? The new ma...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>#3 woke up and was having an accident - &amp;quot;...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                               text  \\\n",
       "213          0  Awwh babs... you look so sad underneith that s...   \n",
       "226          0  Tuesdayï¿½ll start with reflection ï¿½n then a...   \n",
       "279          0  Whinging. My client&amp;boss don't understand ...   \n",
       "343          0  @TheLeagueSF Not Fun &amp; Furious? The new ma...   \n",
       "400          0  #3 woke up and was having an accident - &quot;...   \n",
       "\n",
       "     pre_clean_len  \n",
       "213            142  \n",
       "226            141  \n",
       "279            145  \n",
       "343            145  \n",
       "400            144  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pre_clean_len > 140].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x147801d1ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(df.pre_clean_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whinging. My client&amp;boss don't understand English well. Rewrote some text unreadable. It's written by v. good writer&amp;reviewed correctly. \n",
      "Whinging. My client&boss don't understand English well. Rewrote some text unreadable. It's written by v. good writer&reviewed correctly. \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "example1 = BeautifulSoup(df.text[279], 'lxml')\n",
    "print(df.text[279])\n",
    "print(example1.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@TheLeagueSF Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'@[A-Za-z0-9]+','',df.text[343])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot  - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('https?://[A-Za-z0-9./]+','',df.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@machineplay I'm so sorry you're having to go through this. Again.  #therapyfail\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' machineplay I m so sorry you re having to go through this  Again    therapyfail'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[^a-zA-Z]',' ',df.text[175])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    #Removal of unnecessary spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 10000 of 1600000 has been processed\n",
      "Tweets 20000 of 1600000 has been processed\n",
      "Tweets 30000 of 1600000 has been processed\n",
      "Tweets 40000 of 1600000 has been processed\n",
      "Tweets 50000 of 1600000 has been processed\n",
      "Tweets 60000 of 1600000 has been processed\n",
      "Tweets 70000 of 1600000 has been processed\n",
      "Tweets 80000 of 1600000 has been processed\n",
      "Tweets 90000 of 1600000 has been processed\n",
      "Tweets 100000 of 1600000 has been processed\n",
      "Tweets 110000 of 1600000 has been processed\n",
      "Tweets 120000 of 1600000 has been processed\n",
      "Tweets 130000 of 1600000 has been processed\n",
      "Tweets 140000 of 1600000 has been processed\n",
      "Tweets 150000 of 1600000 has been processed\n",
      "Tweets 160000 of 1600000 has been processed\n",
      "Tweets 170000 of 1600000 has been processed\n",
      "Tweets 180000 of 1600000 has been processed\n",
      "Tweets 190000 of 1600000 has been processed\n",
      "Tweets 200000 of 1600000 has been processed\n",
      "Tweets 210000 of 1600000 has been processed\n",
      "Tweets 220000 of 1600000 has been processed\n",
      "Tweets 230000 of 1600000 has been processed\n",
      "Tweets 240000 of 1600000 has been processed\n",
      "Tweets 250000 of 1600000 has been processed\n",
      "Tweets 260000 of 1600000 has been processed\n",
      "Tweets 270000 of 1600000 has been processed\n",
      "Tweets 280000 of 1600000 has been processed\n",
      "Tweets 290000 of 1600000 has been processed\n",
      "Tweets 300000 of 1600000 has been processed\n",
      "Tweets 310000 of 1600000 has been processed\n",
      "Tweets 320000 of 1600000 has been processed\n",
      "Tweets 330000 of 1600000 has been processed\n",
      "Tweets 340000 of 1600000 has been processed\n",
      "Tweets 350000 of 1600000 has been processed\n",
      "Tweets 360000 of 1600000 has been processed\n",
      "Tweets 370000 of 1600000 has been processed\n",
      "Tweets 380000 of 1600000 has been processed\n",
      "Tweets 390000 of 1600000 has been processed\n",
      "Tweets 400000 of 1600000 has been processed\n",
      "Tweets 410000 of 1600000 has been processed\n",
      "Tweets 420000 of 1600000 has been processed\n",
      "Tweets 430000 of 1600000 has been processed\n",
      "Tweets 440000 of 1600000 has been processed\n",
      "Tweets 450000 of 1600000 has been processed\n",
      "Tweets 460000 of 1600000 has been processed\n",
      "Tweets 470000 of 1600000 has been processed\n",
      "Tweets 480000 of 1600000 has been processed\n",
      "Tweets 490000 of 1600000 has been processed\n",
      "Tweets 500000 of 1600000 has been processed\n",
      "Tweets 510000 of 1600000 has been processed\n",
      "Tweets 520000 of 1600000 has been processed\n",
      "Tweets 530000 of 1600000 has been processed\n",
      "Tweets 540000 of 1600000 has been processed\n",
      "Tweets 550000 of 1600000 has been processed\n",
      "Tweets 560000 of 1600000 has been processed\n",
      "Tweets 570000 of 1600000 has been processed\n",
      "Tweets 580000 of 1600000 has been processed\n",
      "Tweets 590000 of 1600000 has been processed\n",
      "Tweets 600000 of 1600000 has been processed\n",
      "Tweets 610000 of 1600000 has been processed\n",
      "Tweets 620000 of 1600000 has been processed\n",
      "Tweets 630000 of 1600000 has been processed\n",
      "Tweets 640000 of 1600000 has been processed\n",
      "Tweets 650000 of 1600000 has been processed\n",
      "Tweets 660000 of 1600000 has been processed\n",
      "Tweets 670000 of 1600000 has been processed\n",
      "Tweets 680000 of 1600000 has been processed\n",
      "Tweets 690000 of 1600000 has been processed\n",
      "Tweets 700000 of 1600000 has been processed\n",
      "Tweets 710000 of 1600000 has been processed\n",
      "Tweets 720000 of 1600000 has been processed\n",
      "Tweets 730000 of 1600000 has been processed\n",
      "Tweets 740000 of 1600000 has been processed\n",
      "Tweets 750000 of 1600000 has been processed\n",
      "Tweets 760000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b' i just received my G8 viola exam.. and its... well... .. disappointing.. :\\\\..'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 770000 of 1600000 has been processed\n",
      "Tweets 780000 of 1600000 has been processed\n",
      "Tweets 790000 of 1600000 has been processed\n",
      "Tweets 800000 of 1600000 has been processed\n",
      "Tweets 810000 of 1600000 has been processed\n",
      "Tweets 820000 of 1600000 has been processed\n",
      "Tweets 830000 of 1600000 has been processed\n",
      "Tweets 840000 of 1600000 has been processed\n",
      "Tweets 850000 of 1600000 has been processed\n",
      "Tweets 860000 of 1600000 has been processed\n",
      "Tweets 870000 of 1600000 has been processed\n",
      "Tweets 880000 of 1600000 has been processed\n",
      "Tweets 890000 of 1600000 has been processed\n",
      "Tweets 900000 of 1600000 has been processed\n",
      "Tweets 910000 of 1600000 has been processed\n",
      "Tweets 920000 of 1600000 has been processed\n",
      "Tweets 930000 of 1600000 has been processed\n",
      "Tweets 940000 of 1600000 has been processed\n",
      "Tweets 950000 of 1600000 has been processed\n",
      "Tweets 960000 of 1600000 has been processed\n",
      "Tweets 970000 of 1600000 has been processed\n",
      "Tweets 980000 of 1600000 has been processed\n",
      "Tweets 990000 of 1600000 has been processed\n",
      "Tweets 1000000 of 1600000 has been processed\n",
      "Tweets 1010000 of 1600000 has been processed\n",
      "Tweets 1020000 of 1600000 has been processed\n",
      "Tweets 1030000 of 1600000 has been processed\n",
      "Tweets 1040000 of 1600000 has been processed\n",
      "Tweets 1050000 of 1600000 has been processed\n",
      "Tweets 1060000 of 1600000 has been processed\n",
      "Tweets 1070000 of 1600000 has been processed\n",
      "Tweets 1080000 of 1600000 has been processed\n",
      "Tweets 1090000 of 1600000 has been processed\n",
      "Tweets 1100000 of 1600000 has been processed\n",
      "Tweets 1110000 of 1600000 has been processed\n",
      "Tweets 1120000 of 1600000 has been processed\n",
      "Tweets 1130000 of 1600000 has been processed\n",
      "Tweets 1140000 of 1600000 has been processed\n",
      "Tweets 1150000 of 1600000 has been processed\n",
      "Tweets 1160000 of 1600000 has been processed\n",
      "Tweets 1170000 of 1600000 has been processed\n",
      "Tweets 1180000 of 1600000 has been processed\n",
      "Tweets 1190000 of 1600000 has been processed\n",
      "Tweets 1200000 of 1600000 has been processed\n",
      "Tweets 1210000 of 1600000 has been processed\n",
      "Tweets 1220000 of 1600000 has been processed\n",
      "Tweets 1230000 of 1600000 has been processed\n",
      "Tweets 1240000 of 1600000 has been processed\n",
      "Tweets 1250000 of 1600000 has been processed\n",
      "Tweets 1260000 of 1600000 has been processed\n",
      "Tweets 1270000 of 1600000 has been processed\n",
      "Tweets 1280000 of 1600000 has been processed\n",
      "Tweets 1290000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\\\../  \\\\../'\" looks like a filename, not markup. You shouldprobably open this file and pass the filehandle intoBeautiful Soup.\n",
      "  'Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 1300000 of 1600000 has been processed\n",
      "Tweets 1310000 of 1600000 has been processed\n",
      "Tweets 1320000 of 1600000 has been processed\n",
      "Tweets 1330000 of 1600000 has been processed\n",
      "Tweets 1340000 of 1600000 has been processed\n",
      "Tweets 1350000 of 1600000 has been processed\n",
      "Tweets 1360000 of 1600000 has been processed\n",
      "Tweets 1370000 of 1600000 has been processed\n",
      "Tweets 1380000 of 1600000 has been processed\n",
      "Tweets 1390000 of 1600000 has been processed\n",
      "Tweets 1400000 of 1600000 has been processed\n",
      "Tweets 1410000 of 1600000 has been processed\n",
      "Tweets 1420000 of 1600000 has been processed\n",
      "Tweets 1430000 of 1600000 has been processed\n",
      "Tweets 1440000 of 1600000 has been processed\n",
      "Tweets 1450000 of 1600000 has been processed\n",
      "Tweets 1460000 of 1600000 has been processed\n",
      "Tweets 1470000 of 1600000 has been processed\n",
      "Tweets 1480000 of 1600000 has been processed\n",
      "Tweets 1490000 of 1600000 has been processed\n",
      "Tweets 1500000 of 1600000 has been processed\n",
      "Tweets 1510000 of 1600000 has been processed\n",
      "Tweets 1520000 of 1600000 has been processed\n",
      "Tweets 1530000 of 1600000 has been processed\n",
      "Tweets 1540000 of 1600000 has been processed\n",
      "Tweets 1550000 of 1600000 has been processed\n",
      "Tweets 1560000 of 1600000 has been processed\n",
      "Tweets 1570000 of 1600000 has been processed\n",
      "Tweets 1580000 of 1600000 has been processed\n",
      "Tweets 1590000 of 1600000 has been processed\n",
      "Tweets 1600000 of 1600000 has been processed\n"
     ]
    }
   ],
   "source": [
    "nums = [0,400000,800000,1200000,1600000]\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for j in range(0,4):\n",
    "    for i in range(nums[j],nums[j+1]):\n",
    "        if( (i+1)%10000 == 0 ):\n",
    "            print(\"Tweets %d of 1600000 has been processed\" %( i+1))                                                                    \n",
    "        clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df['target'] = df.sentiment\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.to_csv(r'C:\\Users\\Swayam Dutta\\Desktop\\Sentiment Analysis\\clean_tweet.csv',encoding='utf-8')\n",
    "csv = r'C:\\Users\\Swayam Dutta\\Desktop\\Sentiment Analysis\\clean_tweet.csv'\n",
    "my_df = pd.read_csv(csv,index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
